{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV 파일 로드 중...\n",
      "텍스트 전처리 중... (숫자, 큰따옴표 제거)\n",
      "전처리 후 남은 문장 수: 12452\n",
      "사용 중인 디바이스: cuda\n",
      "모델 로드 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`SentenceTransformer._target_device` has been deprecated, please use `SentenceTransformer.device` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델이 로드되었습니다. 모델 디바이스: cuda:0\n",
      "임베딩 생성 중...\n",
      "GPU에서 코사인 유사도 계산 중...\n",
      "유사 문장 제거 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "중복 제거 진행 중: 100%|██████████| 12452/12452 [00:00<00:00, 802931.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "제거할 문장 수: 10472\n",
      "전처리 완료. CSV 파일 저장 중...\n",
      "CSV 파일 저장 완료: daily_conversation_preprocessed.csv\n",
      "                                                text\n",
      "0  오늘은 무슨 영화를 볼까? 나는 전쟁 영화가 보고 싶어. 그런데 너는 어떤 영화를 ...\n",
      "1  네가 요즘 사진 찍는 것에 관심이 많은 것 같아서 물어보려고 해. 어떤 사진을 찍고...\n",
      "2  나는 요즘 새로운 언어를 배우고 싶어. 그런데 어떤 언어를 배워야 할지 결정할 수가...\n",
      "3  나는 요즘 요가에 관심이 많아져서 요가 수업을 듣고 싶어. 그래? 요가는 스트레스를...\n",
      "4  나는 요즘 환경에 대해 더 많은 관심을 가지고 있어. 그리고 내가 어떻게 하면 환경...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm  # 진행 상황 표시용 (pip install tqdm)\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "def preprocess_csv_with_embedding_gpu(\n",
    "    file_path,\n",
    "    output_path,\n",
    "    model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\",\n",
    "    min_length=5,\n",
    "    similarity_threshold=0.9\n",
    "):\n",
    "    # 1. CSV 로드\n",
    "    print(\"CSV 파일 로드 중...\")\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # 2. 기본 전처리: 숫자로 시작하는 부분, 큰따옴표, 모든 숫자 제거\n",
    "    print(\"텍스트 전처리 중... (숫자, 큰따옴표 제거)\")\n",
    "    df[\"generated_dialogue\"] = df[\"generated_dialogue\"].str.replace(\n",
    "        r'^\\d+\\.?\\s*', '', regex=True\n",
    "    )\n",
    "    df[\"generated_dialogue\"] = df[\"generated_dialogue\"].str.replace(\n",
    "        r'\"', '', regex=True\n",
    "    )\n",
    "    df[\"generated_dialogue\"] = df[\"generated_dialogue\"].str.replace(\n",
    "        r'[0-9]+', '', regex=True\n",
    "    )\n",
    "    df.rename(columns={\"generated_dialogue\": \"text\"}, inplace=True)\n",
    "    \n",
    "    # 3. 너무 짧은 문장 제거\n",
    "    df = df[df[\"text\"].str.len() >= min_length].reset_index(drop=True)\n",
    "    print(f\"전처리 후 남은 문장 수: {len(df)}\")\n",
    "    \n",
    "    # 4. GPU 사용 여부 확인\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    print(\"사용 중인 디바이스:\", device)\n",
    "    \n",
    "    # 5. 모델 로드 (GPU/CPU 자동 설정)\n",
    "    print(\"모델 로드 중...\")\n",
    "    model = SentenceTransformer(model_name, device=device)\n",
    "    print(\"모델이 로드되었습니다. 모델 디바이스:\", model._target_device)\n",
    "    \n",
    "    # 6. 임베딩 생성 (GPU에서 생성)\n",
    "    print(\"임베딩 생성 중...\")\n",
    "    texts = df[\"text\"].tolist()\n",
    "    embeddings = model.encode(texts, convert_to_tensor=True)  # Tensor, device=device\n",
    "    \n",
    "    # 7. GPU에서 코사인 유사도 계산 (벡터화 연산)\n",
    "    print(\"GPU에서 코사인 유사도 계산 중...\")\n",
    "    # 정규화\n",
    "    embeddings_norm = torch.nn.functional.normalize(embeddings, p=2, dim=1)\n",
    "    # 전체 유사도 행렬 계산: (n, n)\n",
    "    similarity_matrix = torch.matmul(embeddings_norm, embeddings_norm.T)\n",
    "    # similarity_matrix는 GPU에 있으므로, 이후 반복문 처리를 위해 CPU로 옮깁니다.\n",
    "    similarity_matrix = similarity_matrix.cpu().numpy()\n",
    "    \n",
    "    # 8. 코사인 유사도 기반 중복 제거 (벡터화된 유사도 사용)\n",
    "    print(\"유사 문장 제거 중...\")\n",
    "    to_remove = set()\n",
    "    n = len(df)\n",
    "    for i in tqdm(range(n), desc=\"중복 제거 진행 중\"):\n",
    "        if i in to_remove:\n",
    "            continue\n",
    "        # i번째 행의 i+1부터의 유사도 추출\n",
    "        row_sim = similarity_matrix[i, i+1:]\n",
    "        similar_indices = np.where(row_sim >= similarity_threshold)[0] + i + 1\n",
    "        to_remove.update(similar_indices.tolist())\n",
    "    \n",
    "    print(f\"제거할 문장 수: {len(to_remove)}\")\n",
    "    df = df.drop(list(to_remove)).reset_index(drop=True)\n",
    "    \n",
    "    # 9. 결과 CSV 저장\n",
    "    print(\"전처리 완료. CSV 파일 저장 중...\")\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(\"CSV 파일 저장 완료:\", output_path)\n",
    "    \n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = \"daily_conversation_from_train.csv\"\n",
    "    output_path = \"daily_conversation_preprocessed.csv\"\n",
    "    \n",
    "    df_processed = preprocess_csv_with_embedding_gpu(\n",
    "        file_path=file_path,\n",
    "        output_path=output_path,\n",
    "        model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\",  # 한국어 포함 다국어 모델\n",
    "        min_length=5,\n",
    "        similarity_threshold=0.7\n",
    "    )\n",
    "    print(df_processed.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
